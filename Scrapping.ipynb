{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a476ef1b-5b63-4c4a-82c1-d2feb8831c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scraped and saved dataset from Al Jazeera and Al Arabiya.\n",
      "                                                text  score\n",
      "0  ÙƒØ´ÙØª Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù„Ø§Ø­ÙŠØ© Ø£Ù† Ø³ÙÙŠÙ†Ø© Ù…ØªØ¬Ù‡Ø© Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ Ø±Ø³Øª...    0.3\n",
      "1  Ø®Ø±Ø¬Øª Ù…Ø¸Ø§Ù‡Ø±Ø§Øª Ø­Ø§Ø´Ø¯Ø© ÙÙŠ Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø¹ÙˆØ§ØµÙ… ÙˆØ§Ù„Ù…Ø¯Ù† Ø­Ùˆ...    1.6\n",
      "2  Ø´Ù‡Ø¯Øª Ù…Ù†ØµØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ ÙÙŠ Ù…ØµØ± Ø­Ø§Ù„Ø© Ù…Ù† Ø§Ù„...    9.3\n",
      "3  Ø·ÙˆØª Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø© Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© ÙˆØ¥ÙŠØ±Ø§Ù† ØµÙØ­Ø© Ø§Ù„Ø¬...    2.1\n",
      "4  Ø¹Ø§Ø¯Øª Ø·Ø§Ø¦Ø±Ø© Ø¨ÙˆÙŠÙ†Øº 737 Ù…Ø§ÙƒØ³ ÙƒØ§Ù†Øª Ù…Ø®ØµØµØ© Ù„Ø´Ø±ÙƒØ© Ø·ÙŠØ±...    7.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def scrape_site(url, p_tag='p', min_length=30):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all(p_tag)\n",
    "    texts = [p.get_text().strip() for p in paragraphs if len(p.get_text().strip()) > min_length]\n",
    "    return texts\n",
    "\n",
    "# Scrape Al Jazeera\n",
    "aljazeera_url = \"https://www.aljazeera.net/news\"\n",
    "texts_jazeera = scrape_site(aljazeera_url)\n",
    "\n",
    "# Scrape Al Arabiya\n",
    "alarabiya_url = \"https://www.alarabiya.net/arab-and-world\"\n",
    "texts_arabiya = scrape_site(alarabiya_url)\n",
    "\n",
    "# Combine and assign random scores\n",
    "combined_texts = texts_jazeera[:25] + texts_arabiya[:25]\n",
    "data = [{'text': text, 'score': round(random.uniform(0, 10), 1)} for text in combined_texts]\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('arabic_combined_dataset.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… Scraped and saved dataset from Al Jazeera and Al Arabiya.\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6488692-f3cc-4825-bccd-02c2f0d0d161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessing complete. Sample:\n",
      "                                          clean_text  score\n",
      "0  ÙƒØ´ÙØª Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù„Ø§Ø­ÙŠØ© Ø£Ù† Ø³ÙÙŠÙ†Ø© Ù…ØªØ¬Ù‡Ø© Ù„Ø¥Ø³Ø±Ø§Ø¦ÙŠÙ„ Ø±Ø³Øª...    0.3\n",
      "1  Ø®Ø±Ø¬Øª Ù…Ø¸Ø§Ù‡Ø±Ø§Øª Ø­Ø§Ø´Ø¯Ø© ÙÙŠ Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø¹ÙˆØ§ØµÙ… ÙˆØ§Ù„Ù…Ø¯Ù† Ø­Ùˆ...    1.6\n",
      "2  Ø´Ù‡Ø¯Øª Ù…Ù†ØµØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ ÙÙŠ Ù…ØµØ± Ø­Ø§Ù„Ø© Ù…Ù† Ø§Ù„...    9.3\n",
      "3  Ø·ÙˆØª Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø© Ø§Ù„Ø£Ù…ÙŠØ±ÙƒÙŠØ© ÙˆØ¥ÙŠØ±Ø§Ù† ØµÙØ­Ø© Ø§Ù„Ø¬...    2.1\n",
      "4  Ø¹Ø§Ø¯Øª Ø·Ø§Ø¦Ø±Ø© Ø¨ÙˆÙŠÙ†Øº Ù…Ø§ÙƒØ³ ÙƒØ§Ù†Øª Ù…Ø®ØµØµØ© Ù„Ø´Ø±ÙƒØ© Ø·ÙŠØ±Ø§Ù† Øµ...    7.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "\n",
    "# âœ… Download Arabic stopwords from GitHub\n",
    "stopwords_url = 'https://raw.githubusercontent.com/mohataher/arabicstopwords/master/list.txt'\n",
    "response = requests.get(stopwords_url)\n",
    "arabic_stopwords = set(response.text.splitlines())\n",
    "\n",
    "# âœ… Load the dataset\n",
    "df = pd.read_csv(\"arabic_combined_dataset.csv\")\n",
    "\n",
    "# âœ… Clean and preprocess\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)  # Keep Arabic characters only\n",
    "    text = dediac_ar(text)  # Remove diacritics\n",
    "    tokens = simple_word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in arabic_stopwords]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['clean_text'] = df['text'].apply(preprocess)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(\"âœ… Preprocessing complete. Sample:\")\n",
    "print(df[['clean_text', 'score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e03215-799e-4ee3-99af-c3664f5565a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ Training RNN model...\n",
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 33.2224 - mae: 4.8422 - val_loss: 5.4661 - val_mae: 2.1873\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 28.3096 - mae: 4.3677 - val_loss: 5.0442 - val_mae: 2.1152\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - loss: 23.7490 - mae: 3.9456 - val_loss: 3.9964 - val_mae: 1.8758\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - loss: 19.5147 - mae: 3.4957 - val_loss: 2.4516 - val_mae: 1.3917\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 16.3631 - mae: 3.2190 - val_loss: 1.3487 - val_mae: 0.8923\n",
      "\n",
      "ğŸ”§ Training BiRNN model...\n",
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 31.2876 - mae: 4.6800 - val_loss: 3.2054 - val_mae: 1.5612\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - loss: 24.5906 - mae: 4.0397 - val_loss: 2.2638 - val_mae: 1.2338\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 20.4946 - mae: 3.6100 - val_loss: 1.4862 - val_mae: 0.8907\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 17.4816 - mae: 3.3120 - val_loss: 1.0755 - val_mae: 0.7946\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 15.0823 - mae: 3.0693 - val_loss: 0.8784 - val_mae: 0.7217\n",
      "\n",
      "ğŸ”§ Training GRU model...\n",
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 34.1358 - mae: 4.9557 - val_loss: 6.1761 - val_mae: 2.3246\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 33.7779 - mae: 4.9218 - val_loss: 6.0996 - val_mae: 2.3078\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 33.4180 - mae: 4.8873 - val_loss: 6.0210 - val_mae: 2.2903\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 33.0458 - mae: 4.8510 - val_loss: 5.9390 - val_mae: 2.2721\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 32.6524 - mae: 4.8121 - val_loss: 5.8521 - val_mae: 2.2526\n",
      "\n",
      "ğŸ”§ Training LSTM model...\n",
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 34.2597 - mae: 4.9691 - val_loss: 6.1165 - val_mae: 2.3128\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 33.9502 - mae: 4.9394 - val_loss: 6.0465 - val_mae: 2.2976\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - loss: 33.6316 - mae: 4.9086 - val_loss: 5.9663 - val_mae: 2.2801\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 33.2783 - mae: 4.8742 - val_loss: 5.8713 - val_mae: 2.2593\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 32.8694 - mae: 4.8340 - val_loss: 5.7548 - val_mae: 2.2337\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Tokenize and pad\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['clean_text'])\n",
    "X = tokenizer.texts_to_sequences(df['clean_text'])\n",
    "X = pad_sequences(X, maxlen=100)\n",
    "y = df['score'].values\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build model function\n",
    "def build_model(model_type='RNN'):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
    "\n",
    "    if model_type == 'RNN':\n",
    "        model.add(tf.keras.layers.SimpleRNN(64))\n",
    "    elif model_type == 'BiRNN':\n",
    "        model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(64)))\n",
    "    elif model_type == 'GRU':\n",
    "        model.add(tf.keras.layers.GRU(64))\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(tf.keras.layers.LSTM(64))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1))  # Regression\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Train all models\n",
    "models = ['RNN', 'BiRNN', 'GRU', 'LSTM']\n",
    "trained_models = {}\n",
    "\n",
    "for name in models:\n",
    "    print(f\"\\nğŸ”§ Training {name} model...\")\n",
    "    model = build_model(name)\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=16, validation_split=0.2)\n",
    "    trained_models[name] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4268c925-f0b7-48bf-bd07-20fe2e958a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "\n",
      "ğŸ“Š Evaluation for RNN model:\n",
      "MAE: 1.58\n",
      "MSE: 3.01\n",
      "RÂ² Score: -0.29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
      "\n",
      "ğŸ“Š Evaluation for BiRNN model:\n",
      "MAE: 1.58\n",
      "MSE: 2.52\n",
      "RÂ² Score: -0.08\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "\n",
      "ğŸ“Š Evaluation for GRU model:\n",
      "MAE: 2.33\n",
      "MSE: 7.68\n",
      "RÂ² Score: -2.29\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step\n",
      "\n",
      "ğŸ“Š Evaluation for LSTM model:\n",
      "MAE: 2.35\n",
      "MSE: 7.85\n",
      "RÂ² Score: -2.36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate all models\n",
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    print(f\"\\nğŸ“Š Evaluation for {name} model:\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_test, y_pred):.2f}\")\n",
    "    print(f\"RÂ² Score: {r2_score(y_test, y_pred):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
